{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Redes Neurais -  Consumo de álcool dos estudantes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1INVdBcvHSSVMfbyWF9EFg3XXDoDWtG3M",
      "authorship_tag": "ABX9TyMbHQCUbtSjJC9qwtOWJ4At",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasferreiraos/curso-aprendizado-de-maquina-na-pratica/blob/master/Redes_Neurais_Consumo_de_%C3%A1lcool_dos_estudantes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzdvUeWb9AU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5d8fca48-fcba-461f-894a-566f314edccc"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        " \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_curve\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugFD3LJPAdWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/Datasets/student-alcohol-consumption/student-mat.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzr2R3DlBckM",
        "colab_type": "text"
      },
      "source": [
        "## Pré-processamento dos dados\n",
        "\n",
        "Aqui será executado os mesmo procedimentos adotados com a Árvore de Decisão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoVijJDoAia0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = ['schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']\n",
        "\n",
        "for label in labels:\n",
        "    data[label] = data[label].replace(['yes', 'no'], [1, 0])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjSszqqYCpAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['school'] = data['school'].replace(['GP', 'MS'], [1, 0])\n",
        "data['sex'] = data['sex'].replace(['F', 'M'], [1, 0])\n",
        "data['address'] = data['address'].replace(['U', 'R'], [1, 0])\n",
        "data['famsize'] = data['famsize'].replace(['GT3', 'LE3'], [1, 0])\n",
        "data['Pstatus'] = data['Pstatus'].replace(['T', 'A'], [1, 0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0tIryhzCpoP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "8b3991a5-bdf6-4da4-b989-86e3462d6bfd"
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "data.Mjob = label_encoder.fit_transform(data.Mjob)\n",
        "data.Fjob = label_encoder.fit_transform(data.Fjob)\n",
        "data.reason = label_encoder.fit_transform(data.reason)\n",
        "data.guardian = label_encoder.fit_transform(data.guardian)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>address</th>\n",
              "      <th>famsize</th>\n",
              "      <th>Pstatus</th>\n",
              "      <th>Medu</th>\n",
              "      <th>Fedu</th>\n",
              "      <th>Mjob</th>\n",
              "      <th>Fjob</th>\n",
              "      <th>reason</th>\n",
              "      <th>guardian</th>\n",
              "      <th>traveltime</th>\n",
              "      <th>studytime</th>\n",
              "      <th>failures</th>\n",
              "      <th>schoolsup</th>\n",
              "      <th>famsup</th>\n",
              "      <th>paid</th>\n",
              "      <th>activities</th>\n",
              "      <th>nursery</th>\n",
              "      <th>higher</th>\n",
              "      <th>internet</th>\n",
              "      <th>romantic</th>\n",
              "      <th>famrel</th>\n",
              "      <th>freetime</th>\n",
              "      <th>goout</th>\n",
              "      <th>Dalc</th>\n",
              "      <th>Walc</th>\n",
              "      <th>health</th>\n",
              "      <th>absences</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>G3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   school  sex  age  address  famsize  ...  health  absences  G1  G2  G3\n",
              "0       1    1   18        1        1  ...       3         6   5   6   6\n",
              "1       1    1   17        1        1  ...       3         4   5   5   6\n",
              "2       1    1   15        1        0  ...       3        10   7   8  10\n",
              "3       1    1   15        1        1  ...       5         2  15  14  15\n",
              "4       1    1   16        1        1  ...       5         4   6  10  10\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctnXIlvVDxe1",
        "colab_type": "text"
      },
      "source": [
        "### Tratando o caso do desbalanceamento entre as classes\n",
        "\n",
        "O gráfico abaixo vai nos mostrar que existe um desbalanceamento muito grande, é possível notar que a classe majoritária (nota 10) contém muito mais instâncias que as outras classes, inclusive a classe minoritária (nota 20). Pelo fato de que esses dados representam, em linhas gerais, o rendimento dos alunos do ensino secundário, nos leva a concluir que o comportamento dos dados representa bem o contexto.\n",
        "\n",
        "Porém, mesmo sendo uma característica do contexto, tal comportamento pode ser um impeditivo na performance do classificador - além da baixa quantidade de instâncias no dataset - por ter muitas classes com um desbalanceamento muito evidente.\n",
        "\n",
        "Podemos tomar algumas dessas decisões:\n",
        "- Treinar o modelo com o dataset desbalanceado;\n",
        "- Diminuir o número de classes;\n",
        "- Balancear o dataset utilizando resampling e diminuir o número de classes;\n",
        "\n",
        "A última abordagem se mostrou bem eficaz para a Árvore de Decisão. Contudo, se queremos a melhor abordagem no pré-processamento, vamos testar os 3 caminhos e discutir os resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkBLBItVD6aH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "bc38be44-3e00-4d15-c06f-7919ab9b5fd4"
      },
      "source": [
        "target_count = data.G3.value_counts()\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Total de instâncias')\n",
        "target_count.plot(kind='bar', title='Contagem de classes (G3)')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3209c4c320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q22lU_pqK4gQ",
        "colab_type": "text"
      },
      "source": [
        "## Treinando a Rede Neural com dataset desbalanceado e as classes originais."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxvxFE_uED3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "3986df6c-4e85-4ce6-cabb-55715f9016d0"
      },
      "source": [
        "X = data.iloc[:, :-1]\n",
        "y = data.G3\n",
        "\n",
        "X = (X - X.min()) / (X.max() - X.min())\n",
        "X.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>address</th>\n",
              "      <th>famsize</th>\n",
              "      <th>Pstatus</th>\n",
              "      <th>Medu</th>\n",
              "      <th>Fedu</th>\n",
              "      <th>Mjob</th>\n",
              "      <th>Fjob</th>\n",
              "      <th>reason</th>\n",
              "      <th>guardian</th>\n",
              "      <th>traveltime</th>\n",
              "      <th>studytime</th>\n",
              "      <th>failures</th>\n",
              "      <th>schoolsup</th>\n",
              "      <th>famsup</th>\n",
              "      <th>paid</th>\n",
              "      <th>activities</th>\n",
              "      <th>nursery</th>\n",
              "      <th>higher</th>\n",
              "      <th>internet</th>\n",
              "      <th>romantic</th>\n",
              "      <th>famrel</th>\n",
              "      <th>freetime</th>\n",
              "      <th>goout</th>\n",
              "      <th>Dalc</th>\n",
              "      <th>Walc</th>\n",
              "      <th>health</th>\n",
              "      <th>absences</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.1250</td>\n",
              "      <td>0.315789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.053333</td>\n",
              "      <td>0.1250</td>\n",
              "      <td>0.263158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>0.421053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.026667</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.736842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.053333</td>\n",
              "      <td>0.1875</td>\n",
              "      <td>0.526316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   school  sex       age  address  ...  health  absences      G1        G2\n",
              "0     1.0  1.0  0.428571      1.0  ...     0.5  0.080000  0.1250  0.315789\n",
              "1     1.0  1.0  0.285714      1.0  ...     0.5  0.053333  0.1250  0.263158\n",
              "2     1.0  1.0  0.000000      1.0  ...     0.5  0.133333  0.2500  0.421053\n",
              "3     1.0  1.0  0.000000      1.0  ...     1.0  0.026667  0.7500  0.736842\n",
              "4     1.0  1.0  0.142857      1.0  ...     1.0  0.053333  0.1875  0.526316\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIawbf_ET9UA",
        "colab_type": "text"
      },
      "source": [
        "### Otimização de parâmetros\n",
        "\n",
        "Já que vamos testar todas as hipóteses em relação ao pré-processamento, vamos buscar o melhor conjunto de parâmetros para o nosso modelo e ver o seu resultado. Abaixo eu defini uma estrutura que se chama **espaço de soluções**, que é um conjunto de possíveis parâmetros para uma rede neural. A partir desse conjunto vamos tentar buscar pela melhor solução para todas as hipóteses que testarmos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySz1KV7sMKDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = [{\n",
        "    'hidden_layer_sizes': [(30), (50, 30), (50, 100), (30, 50, 100), (50, 150, 100)],\n",
        "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
        "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
        "    'max_iter': [500, 1000, 2000]\n",
        "}]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vFaCbBtYHRQ",
        "colab_type": "text"
      },
      "source": [
        "### Método de busca\n",
        "\n",
        "Vamos utilizar o **Randomized Search** como método de busca do melhor conjunto de parâmetros. Como o nome sugere, ele faz uma escolha aleatória dos parâmetros existentes no espaço de soluções e te entrega a melhor configuração. Por ser aleatório, ele pode acabar desconsiderando alguma combinação que possivelmente poderia ser a melhor; por outro lado, esse método é o que possui o menor tempo de execução e por isso vamos seguir com ele.\n",
        "\n",
        "### Validação cruzada e métricas\n",
        "\n",
        "Para a validação cruzada vamos definir `k = 10` e como métrica de score vamos usar a acurácia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWLm6YG1Xnx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_01 = RandomizedSearchCV(\n",
        "    MLPClassifier(),\n",
        "    param_grid,\n",
        "    cv=10,\n",
        "    scoring='accuracy'\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0eUakqtb_0v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a3ca1c34-6a02-4403-fdee-2ba3d4a18c95"
      },
      "source": [
        "mlp_01.fit(X, y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=10, error_score=nan,\n",
              "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                           batch_size='auto', beta_1=0.9,\n",
              "                                           beta_2=0.999, early_stopping=False,\n",
              "                                           epsilon=1e-08,\n",
              "                                           hidden_layer_sizes=(100,),\n",
              "                                           learning_rate='constant',\n",
              "                                           learning_rate_init=0.001,\n",
              "                                           max_fun=15000, max_iter=200,\n",
              "                                           momentum=0.9, n_iter_no_change=10,\n",
              "                                           nesterovs_momentum=True, power_t=0.5,\n",
              "                                           rando...\n",
              "                                           verbose=False, warm_start=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions=[{'activation': ['identity', 'logistic',\n",
              "                                                        'tanh', 'relu'],\n",
              "                                         'hidden_layer_sizes': [30, (50, 30),\n",
              "                                                                (50, 100),\n",
              "                                                                (30, 50, 100),\n",
              "                                                                (50, 150, 100)],\n",
              "                                         'max_iter': [500, 1000, 2000],\n",
              "                                         'solver': ['lbfgs', 'sgd', 'adam']}],\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgvl5PaBcx9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f550b919-8ea1-4547-e95a-15da146fca16"
      },
      "source": [
        "mlp_01_best_params = mlp_01.best_params_\n",
        "\n",
        "print('BEST PARAMETERS')\n",
        "for key, value in mlp_01_best_params.items():\n",
        "    print(key + ':', value)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BEST PARAMETERS\n",
            "solver: adam\n",
            "max_iter: 2000\n",
            "hidden_layer_sizes: (50, 150, 100)\n",
            "activation: identity\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URthsrVsdVX2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3d38b08-451b-4376-9c5e-5924c3bd49ba"
      },
      "source": [
        "print('Accuracy:', round(mlp_01.best_score_, 3)*100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 37.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfqZKKowimmC",
        "colab_type": "text"
      },
      "source": [
        "## Discutindo resultados do primeiro modelo\n",
        "\n",
        "Vemos que a acurácia foi muito baixa mesmo com a melhor configuração para o modelo. Muito provavelmente isso se deve a questão do alto desbalanceamento das classes.\n",
        "\n",
        "Dentro da hipóteses que foram levantadas, acredito que podemos adotar duas delas para a próxima análise:\n",
        "- Balancear o dataset\n",
        "- Diminuir o número de classes\n",
        "\n",
        "Vamos diminuir o número das classes primeiramente e ver o resultado que obeteremos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T7rNLf6pV_s",
        "colab_type": "text"
      },
      "source": [
        "## Treinando o modelo com o redimensionamento do número de classes\n",
        "\n",
        "Antes de mais nada, é necessário explicar o que se quer dizer com \"diminuir\" o número de classes.\n",
        "\n",
        "Basicamente isso significa associar uma faixa de valores a um novo valor. Geralmente esse novo valor é um valor categórico, por exemplo: imagine notas de 0 a 10 e imagine que, para cada aluno, existe um métrica de desepenho dividida em 3 status:\n",
        "\n",
        "- APROVADO: notas entre 7 e 10\n",
        "- RECUPERAÇÃO: notas entre 5 e 7\n",
        "- REPROVADO: notas entre 0 e 5.\n",
        "\n",
        "Como temos que passar nossos dados para o modelo, o novo valor deve ser numérico. Esse procedimento já foi feito para as árvores de decisão onde eu agrupei as antigas classes em 5 novas classes, de 0 a 4, onde 0 representa as menores faixas de valores de notas e 4 representa as maiores faixas de valores. Vamos repetir esse processo aqui."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S4irfOdb0-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['G3'] = data['G3'].replace([0, 1, 2, 3, 4], 0)\n",
        "data['G3'] = data['G3'].replace([5, 6, 7, 8], 1)\n",
        "data['G3'] = data['G3'].replace([9, 10, 11, 12], 2)\n",
        "data['G3'] = data['G3'].replace([13, 14, 15, 16], 3)\n",
        "data['G3'] = data['G3'].replace([17, 18, 19, 20], 4)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlIO-2N7cDRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "769f1a1a-38f2-46e6-f133-56336884efcf"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>address</th>\n",
              "      <th>famsize</th>\n",
              "      <th>Pstatus</th>\n",
              "      <th>Medu</th>\n",
              "      <th>Fedu</th>\n",
              "      <th>Mjob</th>\n",
              "      <th>Fjob</th>\n",
              "      <th>reason</th>\n",
              "      <th>guardian</th>\n",
              "      <th>traveltime</th>\n",
              "      <th>studytime</th>\n",
              "      <th>failures</th>\n",
              "      <th>schoolsup</th>\n",
              "      <th>famsup</th>\n",
              "      <th>paid</th>\n",
              "      <th>activities</th>\n",
              "      <th>nursery</th>\n",
              "      <th>higher</th>\n",
              "      <th>internet</th>\n",
              "      <th>romantic</th>\n",
              "      <th>famrel</th>\n",
              "      <th>freetime</th>\n",
              "      <th>goout</th>\n",
              "      <th>Dalc</th>\n",
              "      <th>Walc</th>\n",
              "      <th>health</th>\n",
              "      <th>absences</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>G3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   school  sex  age  address  famsize  ...  health  absences  G1  G2  G3\n",
              "0       1    1   18        1        1  ...       3         6   5   6   1\n",
              "1       1    1   17        1        1  ...       3         4   5   5   1\n",
              "2       1    1   15        1        0  ...       3        10   7   8   2\n",
              "3       1    1   15        1        1  ...       5         2  15  14   3\n",
              "4       1    1   16        1        1  ...       5         4   6  10   2\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0KecMyWcFGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "86a3457c-f889-4aa2-e905-3e48ea5c2261"
      },
      "source": [
        "target_count = data.G3.value_counts()\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Total de instâncias')\n",
        "target_count.plot(kind='bar', title='Contagem de classes (G3)')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3205b1a080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAG2CAYAAADRD5oFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7hcVX3/8fdHrqIiSFKEBAgKaPHC5RfxVlsQL1hUbH9qwQtoqakKXusFtRW12h/VolKtFxQE1IKIVlEQRSpSraIBAQmgIIIEA4nKRRSRkO/vj9lHx5hzMiSZWSdn3q/nOc/MXnvNnu/sOc/JJ2uvvXeqCkmSJLVzj9YFSJIkjTsDmSRJUmMGMkmSpMYMZJIkSY0ZyCRJkhozkEmSJDVmIJM0dpK8Jckn1vE2X5DkG+tym8OS5JtJ9liH2zs6yUvW1fakcWQgk2a4JM9JsjDJbUmWJPlSkj9bB9s9Icnb10WNGp0kTwN+WVXf62vbOckpSZYluTXJlUnel2Rut37X7nfopu7nq0l27dvsvwFvTLLxiD+ONGMYyKQZLMmrgfcC/wJsDWwPfAA4oGVdaurFwMcnFpLsBJwP/BTYo6o2Bx4L/AiYCO4/BZ4J3A+YBZwOnDKxjapaAlwBPH0E9UszkoFMmqGS3Bd4G3BYVX22qn5VVXdW1Req6rVdn02SvDfJT7uf9ybZpFu3d5LFSf4hydJudO2F3boFwHOB13Ujb1/o2o9I8qMkv0xyWZK/6qtng+7Q1s+S/DjJ4UkqyYYT9SY5rnuf65O8PckG3boXdIfZ3pPk5iRXJ3lM135dV98hU+yLHZN8vavrbHqhon/9o5L8b7fti5PsPcW2tkvy2W406edJ3j9Jv2O62m5NckGSx/Wt26sbcbo1yY1J3t21b5rkE912b07y3SRbD7B/duo+3y3d/v3UJDVtDDwe+Hpf81uAb1bVq6tqMUBVLa2q91bVKd3yzVV1TfVu7RLgLmCnlTZ/LrD/ZPtN0tQMZNLM9WhgU+C/pujzJuBRwO7AbsBewD/2rb8/cF9gDnAo8B9JtqyqY4FPAu+sqntX1dO6/j8CHte95q3AJ5Js0617EfCU7r32BJ6xUi0nAMvp/UO/B/Ak4O/61j8SuATYCvhPeiM0j+j6Pw94f5J7T/I5/xO4gF4Q+2fgd+EtyRzgDODt9EaAXgN8JsnslTfSBaAvAtcC87r9csrK/Trf7T7r/br3/3SSTbt1xwDHdKNRDwRO7doPobfvtus+54uB2wfYP/8MfAXYEpgLvG+SmnYGVkwEr84TgM9M0v8PJLkZ+E23/X9ZafXl9H6HJK0BA5k0c20F/Kyqlk/R57nA27oRkWX0QtTz+9bf2a2/s6rOBG4DHjTZxqrq01X106paUVWfAq6kF/IAnk0vhCyuqpuAoyZe140C/SXwym4kbynwHuDAvs3/uKo+VlV3AZ+iF1reVlV3VNVXgN/yx6M2JNmeXnD7p67vecAX+ro8Dzizqs7s6j4bWNjVs7K9gG2B13Z1/qaqVjmRv6o+UVU/r6rlVXU0sEnfvrsT2CnJrKq6raq+3de+FbBTVd1VVRdU1a0D7J87gR2AbaeqCdgC+OVKbbOAG/r21+Hd6NxtST6y0mfagl5gPBz43h9uhl9225e0Bgxk0sz1c2DWxCHBSWxLb7RnwrVd2++2sVKg+zUw2SgUSQ5OclH3D/rNwEP5/eHBbYHr+rr3P98B2AhY0vfaDwN/0tfnxr7ntwNU1cptq6ptW+CmqvpVX1v/Z94BeNbE+3bv/WfANvyx7YBrVxNyAUjymiSXd4cRb6YXZCb2xaHALsAV3WHJp3btHwe+DJzSHUJ+Z5KNWP3+eR29Q4nfSbIoyd9OUtZNwH1Wavt5/2etqvd3weu93Xv+gW4/fgg4KUn/93Mf4ObV7RdJqzbVH2pJ67dvAXfQOzR42iR9fkrvH/tF3fL2Xdsgqn8hyQ7AR4B9gW9V1V1JLqIXFACW0DucNmG7vufXdbXOGiTs3E1LgC2T3KsvlG3fV/91wMer6kUDbOs6YPskG05VZzdf7HX09sWiqlqR5Ca6fVFVVwIHJbkH8NfAaUm26up7K/DWJPOAM4EfdI+T7p+quoHeIWHSO4P2q0nOq6qrVup6Va9L5lTV9V3bOV0NHxvg80+4B7AZvUO2S7u2PwUuvhvbkNTHETJphqqqW4A305v39YwkmyXZKMlTkryz63Yy8I9JZieZ1fUf9PpcNwIP6Fu+F72QswwgvRMAHtq3/lTgFUnmJNkCeH1frUvozYE6OsnmSe6R5IFJ/uJuf/CVVNW19A5BvjXJxl1geVpfl08AT0vy5PROPNg0vRMa5q5ic9+hF/COSnKvru9jV9HvPvTmey0DNkzyZmDziZVJnpdkdlWt4PejSiuS7JPkYd1ctVvpHYpcsbr9k+RZffXeRO97WLGKffFb4KtA/359C/C4JO/u5tPR/S78aV+9T0yyR7d/Ngfe3b3P5X3b+QvgS6vYF5IGYCCTZrBu7tKr6U3UX0ZvhOdw4HNdl7fTCyuXAN8HLuzaBnEcsGt3CO1zVXUZcDS9kbkbgYcB3+zr/xF6oeISevOPzqQXWu7q1h8MbAxcRu8f+9NY9WHDNfEceicF/AI4EjhpYkVVXUfvMiBv5Pf76LWs4u9jN3/tafTmqv0EWAz8zSre78vAWcAP6R0e/Q1/eIh2P2BRktvoTfA/sKpup3cSxWn0wtjl9M6GnLhExVT75xHA+d32TgdeUVVXT7IvPkzfPMGq+mG3b+YCFyf5Jb3v7afAP3XdtqAX3m+hd+LGA4H9quo3AN2JG7vy+98rSXdTemcxS9JoJXkK8KGq2qF1LeMmyTeBw/svDruW2zsa+FFVfWBdbE8aRwYySSOR5J7APvRGybamd6mFb1fVK5sWJknTgIFM0kgk2YzeIbgH0zsj8gx6h9ZubVqYJE0DBjJJkqTGnNQvSZLUmIFMkiSpsfX6wrCzZs2qefPmtS5DkiRptS644IKfVdUf3ScX1vNANm/ePBYuXNi6DEmSpNVKcu1k6zxkKUmS1JiBTJIkqTEDmSRJUmMGMkmSpMYMZJIkSY0ZyCRJkhozkEmSJDVmIJMkSWrMQCZJktSYgUySJKkxA5kkSVJjBjJJkqTGDGSSJEmNGcgkSZIaM5BJkiQ1ZiCTJElqbMPWBaxP5h1xRusShuqao/ZvXYIkSWNpaCNkSY5PsjTJpSu1vyzJFUkWJXlnX/sbklyV5AdJnjysuiRJkqabYY6QnQC8HzhpoiHJPsABwG5VdUeSP+nadwUOBB4CbAt8NckuVXXXEOuTJEmaFoY2QlZV5wG/WKn5JcBRVXVH12dp134AcEpV3VFVPwauAvYaVm2SJEnTyagn9e8CPC7J+Um+nuQRXfsc4Lq+fou7tj+SZEGShUkWLlu2bMjlSpIkDd+oA9mGwP2ARwGvBU5Nkruzgao6tqrmV9X82bNnD6NGSZKkkRp1IFsMfLZ6vgOsAGYB1wPb9fWb27VJkiTNeKMOZJ8D9gFIsguwMfAz4HTgwCSbJNkR2Bn4zohrkyRJamJoZ1kmORnYG5iVZDFwJHA8cHx3KYzfAodUVQGLkpwKXAYsBw7zDEtJkjQuhhbIquqgSVY9b5L+7wDeMax6JEmSpitvnSRJktSYgUySJKkxA5kkSVJjBjJJkqTGDGSSJEmNGcgkSZIaM5BJkiQ1ZiCTJElqzEAmSZLUmIFMkiSpMQOZJElSYwYySZKkxgxkkiRJjRnIJEmSGjOQSZIkNWYgkyRJasxAJkmS1JiBTJIkqTEDmSRJUmMGMkmSpMYMZJIkSY0ZyCRJkhozkEmSJDVmIJMkSWrMQCZJktSYgUySJKkxA5kkSVJjBjJJkqTGDGSSJEmNGcgkSZIaM5BJkiQ1ZiCTJElqzEAmSZLUmIFMkiSpMQOZJElSYwYySZKkxoYWyJIcn2RpkktXse4fklSSWd1ykvx7kquSXJJkz2HVJUmSNN0Mc4TsBGC/lRuTbAc8CfhJX/NTgJ27nwXAB4dYlyRJ0rQytEBWVecBv1jFqvcArwOqr+0A4KTq+TawRZJthlWbJEnSdDLSOWRJDgCur6qLV1o1B7iub3lx17aqbSxIsjDJwmXLlg2pUkmSpNEZWSBLshnwRuDNa7Odqjq2quZX1fzZs2evm+IkSZIa2nCE7/VAYEfg4iQAc4ELk+wFXA9s19d3btcmSZI0441shKyqvl9Vf1JV86pqHr3DkntW1Q3A6cDB3dmWjwJuqaolo6pNkiSppWFe9uJk4FvAg5IsTnLoFN3PBK4GrgI+Arx0WHVJkiRNN0M7ZFlVB61m/by+5wUcNqxaJEmSpjOv1C9JktSYgUySJKkxA5kkSVJjBjJJkqTGDGSSJEmNGcgkSZIaM5BJkiQ1ZiCTJElqzEAmSZLUmIFMkiSpMQOZJElSYwYySZKkxgxkkiRJjRnIJEmSGjOQSZIkNWYgkyRJasxAJkmS1JiBTJIkqTEDmSRJUmMGMkmSpMYMZJIkSY0ZyCRJkhozkEmSJDVmIJMkSWrMQCZJktSYgUySJKkxA5kkSVJjBjJJkqTGDGSSJEmNGcgkSZIaM5BJkiQ1ZiCTJElqzEAmSZLUmIFMkiSpMQOZJElSY0MLZEmOT7I0yaV9be9KckWSS5L8V5It+ta9IclVSX6Q5MnDqkuSJGm6GeYI2QnAfiu1nQ08tKoeDvwQeANAkl2BA4GHdK/5QJINhlibJEnStDG0QFZV5wG/WKntK1W1vFv8NjC3e34AcEpV3VFVPwauAvYaVm2SJEnTScs5ZH8LfKl7Pge4rm/d4q5NkiRpxmsSyJK8CVgOfHINXrsgycIkC5ctW7bui5MkSRqxkQeyJC8Ango8t6qqa74e2K6v29yu7Y9U1bFVNb+q5s+ePXuotUqSJI3CSANZkv2A1wFPr6pf9606HTgwySZJdgR2Br4zytokSZJa2XBYG05yMrA3MCvJYuBIemdVbgKcnQTg21X14qpalORU4DJ6hzIPq6q7hlWbJEnSdDK0QFZVB62i+bgp+r8DeMew6pEkSZquvFK/JElSYwYySZKkxgxkkiRJjRnIJEmSGjOQSZIkNWYgkyRJasxAJkmS1JiBTJIkqTEDmSRJUmMGMkmSpMYMZJIkSY0ZyCRJkhozkEmSJDVmIJMkSWrMQCZJktSYgUySJKkxA5kkSVJjBjJJkqTGDGSSJEmNGcgkSZIaM5BJkiQ1ZiCTJElqzEAmSZLUmIFMkiSpsQ1bFyCNyrwjzmhdwlBdc9T+rUuQJK0hR8gkSZIaM5BJkiQ1ZiCTJElqzEAmSZLU2GoDWZJ3Jtk8yUZJzkmyLMnzRlGcJEnSOBhkhOxJVXUr8FTgGmAn4LXDLEqSJGmcDBLIJi6NsT/w6aq6ZYj1SJIkjZ1BrkP2xSRXALcDL0kyG/jNcMuSJEkaH6sdIauqI4DHAPOr6k7gV8ABwy5MkiRpXAx6pf5tgSck2bSv7aQh1CNJkjR2VhvIkhwJ7A3sCpwJPAX4BgYySZKkdWKQSf3PBPYFbqiqFwK7Afdd3YuSHJ9kaZJL+9rul+TsJFd2j1t27Uny70muSnJJkj3X8PNIkiStdwYJZLdX1QpgeZLNgaXAdgO87gRgv5XajgDOqaqdgXO6ZeiNuu3c/SwAPjjA9iVJkmaEQQLZwiRbAB8BLgAuBL61uhdV1XnAL1ZqPgA4sXt+IvCMvvaTqufbwBZJthmgNkmSpPXeaueQVdVLu6cfSnIWsHlVXbKG77d1VS3pnt8AbN09nwNc19dvcde2BEmSpBlu0kCW5MFVdcWq5nMl2bOqLlybN66qSlJ393VJFtA7rMn222+/NiVIkiRNC1ONkL2aXvA5ehXrCnj8GrzfjUm2qaol3SHJpV379fzhvLS5Xdsfv3HVscCxAPPnz7/bgU6SJGm6mTSQVdWC7nGfdfh+pwOHAEd1j5/vaz88ySnAI4Fb+g5tSpIkzWirndSf5LBuUv/E8pZJXjrVa7p+J9Ob/P+gJIuTHEoviD0xyZXAE7pl6F3f7GrgKnonD6x2+5IkSTPFIFfqf1FV/cfEQlXdlORFwAemelFVHTTJqn1X0beAwwaoRZIkacYZ5LIXGyTJxEKSDYCNh1eSJEnSeBlkhOws4FNJPtwt/33XJkmSpHVgkED2enoh7CXd8tnAR4dWkSRJ0pgZ5MKwK+jdysjbGUmSJA3BagNZkscCbwF26PqH3jz8Bwy3NEmSpPEwyCHL44BX0buP5V3DLUeSJGn8DBLIbqmqLw29EkmSpDE1SCD7WpJ3AZ8F7phoXNt7WUqSJKlnkED2yO5xfl/bmt7LUpIkSSsZ5CzLdXkvS0mSJK1kkBEykuwPPATYdKKtqt42rKIkSZLGyaSBLMkDgJ2AvwY2A/ahd0HYZwLfGUl1kiRJY2CV97JM8izgbfSC12Oq6mDgpqp6K/BoYJfRlShJkjSzTXZz8UvojZ49DLi9a/t1km2BO4FtRlCbJEnSWFjlIcuq+gFwYJL7A19MsgXwLuBCemdYei9LSZKkdWTKSf1VdUOSd1bVHcBnknyR3sT+34ykOkmSpDEw2SHLft+aeFJVd1TVLf1tkiRJWjtTnWV5f2AOcM8ke9C7qTjA5vTOupQkSdI6MNUhyycDLwDmAkfz+0D2S+CNwy1LkiRpfEwayKrqRODEJP+3qj4zwpokSZLGyiBzyOYm2Tw9H01yYZInDb0ySZKkMTFIIPvbqroVeBKwFfB84KihViVJkjRGBglkE3PH/hI4qaoW9bVJkiRpLQ0SyC5I8hV6gezLSe4DrBhuWZIkSeNjygvDdg4FdgeurqpfJ9kKeOFwy5IkSRofqw1kVbUiyY3ArkkGCXCSJEm6G1YbsJL8K/A3wGXAXV1zAecNsS5JkqSxMciI1zOAB3X3s5QkSdI6Nsik/quBjYZdiCRJ0rgaZITs18BFSc4BfjdKVlUvH1pVkiRJY2SQQHZ69yNJkqQhGOQsyxNHUYgkSdK4mjSQJTm1qp6d5Pv0zqr8A1X18KFWJkmSNCamGiF7Rff41FEUIkmSNK4mDWRVtaR7vHZ05UiSJI2fQS57IUmSpCFqEsiSvCrJoiSXJjk5yaZJdkxyfpKrknwqycYtapMkSRq1gQJZknsmedC6eMMkc4CXA/Or6qHABsCBwL8C76mqnYCb6N3UXJIkacZbbSBL8jTgIuCsbnn3JGt7XbINgXt2NyvfDFgCPB44rVt/Ir1bNkmSJM14g4yQvQXYC7gZoKouAnZc0zesquuBfwN+Qi+I3QJcANxcVcu7bouBOat6fZIFSRYmWbhs2bI1LUOSJGnaGCSQ3VlVt6zU9kfXJRtUki2BA+iFum2BewH7Dfr6qjq2quZX1fzZs2evaRmSJEnTxiCBbFGS5wAbJNk5yfuA/12L93wC8OOqWlZVdwKfBR4LbNEdwgSYC1y/Fu8hSZK03hgkkL0MeAi9G4ufDNwKvHIt3vMnwKOSbJYkwL7AZcDXgGd2fQ4BPr8W7yFJkrTeGORelr8G3tT9rLWqOj/JacCFwHLge8CxwBnAKUne3rUdty7eT5Ikabqb6l6WX2CKuWJV9fQ1fdOqOhI4cqXmq+mdPCBJkjRWphoh+7fu8a+B+wOf6JYPAm4cZlGSJEnjZKp7WX4dIMnRVTW/b9UXkiwcemWSJEljYpBJ/fdK8oCJhSQ70rtUhSRJktaB1U7qB14FnJvkaiDADsCCoVYlSZI0RgY5y/KsJDsDD+6arqiqO4ZbliRJ0vgYZISMLoBdPORaJEmSxtIgc8gkSZI0RAYySZKkxqa6MOyeU72wqi5c9+VIkiSNn6nmkB09xboCHr+Oa5EkSRpLU10Ydp9RFiJJkjSuBjrLMslDgV2BTSfaquqkYRUlSZI0TlYbyJIcCexNL5CdCTwF+AZgIJMkSVoHBjnL8pnAvsANVfVCYDfgvkOtSpIkaYwMEshur6oVwPIkmwNLge2GW5YkSdL4GGQO2cIkWwAfAS4AbgO+NdSqJEmSxsgg97J8aff0Q0nOAjavqkuGW5YkSdL4WO0hyyTnTDyvqmuq6pL+NkmSJK2dqa7UvymwGTAryZZAulWbA3NGUJskSdJYmOqQ5d8DrwS2Bfpvk3Qr8P5hFiVJkjROprpS/zHAMUleVlXvG2FNkiRJY2WQsyw/nOTlwJ93y+cCH66qO4dWlSRJ0hgZJJB9ANioewR4PvBB4O+GVZQkSdI4mWpS/4ZVtRx4RFXt1rfqv5NcPPzSJEmSxsNUl734Tvd4V5IHTjQmeQBw11CrkiRJGiNTHbKcuMzFa4CvJbm6W54HvHCYRUmSJI2TqQLZ7CSv7p5/GNige34XsAfwtWEWJkmSNC6mCmQbAPfm9yNl/a+5z9AqkiRJGjNTBbIlVfW2kVUiSZI0pqaa1L/yyJgkSZKGYKpAtu/IqpAkSRpjkwayqvrFKAuRJEkaV4NcqV+Smpp3xBmtSxiqa47av3UJkhqb6pClJEmSRsBAJkmS1FiTQJZkiySnJbkiyeVJHp3kfknOTnJl97hli9okSZJGrdUI2THAWVX1YGA34HLgCOCcqtoZOKdbliRJmvFGHsiS3Bf4c+A4gKr6bVXdDBwAnNh1OxF4xqhrkyRJaqHFCNmOwDLgY0m+l+SjSe4FbF1VS7o+NwBbN6hNkiRp5FoEsg2BPYEPVtUewK9Y6fBkVRVQq3pxkgVJFiZZuGzZsqEXK0mSNGwtAtliYHFVnd8tn0YvoN2YZBuA7nHpql5cVcdW1fyqmj979uyRFCxJkjRMIw9kVXUDcF2SB3VN+wKXAacDh3RthwCfH3VtkiRJLbS6Uv/LgE8m2Ri4GnghvXB4apJDgWuBZzeqTZIkaaSaBLKqugiYv4pV3tBckiSNHa/UL0mS1JiBTJIkqTEDmSRJUmMGMkmSpMYMZJIkSY0ZyCRJkhozkEmSJDVmIJMkSWrMQCZJktSYgUySJKkxA5kkSVJjBjJJkqTGDGSSJEmNGcgkSZIaM5BJkiQ1ZiCTJElqzEAmSZLUmIFMkiSpMQOZJElSYwYySZKkxgxkkiRJjRnIJEmSGjOQSZIkNWYgkyRJasxAJkmS1JiBTJIkqTEDmSRJUmMGMkmSpMYMZJIkSY0ZyCRJkhozkEmSJDVmIJMkSWrMQCZJktSYgUySJKkxA5kkSVJjBjJJkqTGmgWyJBsk+V6SL3bLOyY5P8lVST6VZONWtUmSJI1SyxGyVwCX9y3/K/CeqtoJuAk4tElVkiRJI9YkkCWZC+wPfLRbDvB44LSuy4nAM1rUJkmSNGqtRsjeC7wOWNEtbwXcXFXLu+XFwJwWhUmSJI3ayANZkqcCS6vqgjV8/YIkC5MsXLZs2TquTpIkafRajJA9Fnh6kmuAU+gdqjwG2CLJhl2fucD1q3pxVR1bVfOrav7s2bNHUa8kSdJQbbj6LutWVb0BeANAkr2B11TVc5N8GngmvZB2CPD5UdcmSVr35h1xRusShuqao/ZvXYJmgOl0HbLXA69OchW9OWXHNa5HkiRpJEY+Qtavqs4Fzu2eXw3s1bIeSZKkFqbTCJkkSdJYMpBJkiQ1ZiCTJElqzEAmSZLUmIFMkiSpMQOZJElSYwYySZKkxgxkkiRJjRnIJEmSGjOQSZIkNWYgkyRJasxAJkmS1JiBTJIkqTEDmSRJUmMGMkmSpMYMZJIkSY0ZyCRJkhozkEmSJDVmIJMkSWrMQCZJktSYgUySJKkxA5kkSVJjBjJJkqTGDGSSJEmNGcgkSZIaM5BJkiQ1ZiCTJElqzEAmSZLUmIFMkiSpMQOZJElSYwYySZKkxjZsXYAkSZq+5h1xRusShuaao/ZvXcLvOEImSZLUmIFMkiSpMQOZJElSYwYySZKkxkYeyJJsl+RrSS5LsijJK7r2+yU5O8mV3eOWo65NkiSphRYjZMuBf6iqXYFHAYcl2RU4AjinqnYGzumWJUmSZryRB7KqWlJVF3bPfwlcDswBDgBO7LqdCDxj1LVJkiS10HQOWZJ5wB7A+cDWVbWkW3UDsHWjsiRJkkaqWSBLcm/gM8Arq+rW/nVVVUBN8roFSRYmWbhs2bIRVCpJkjRcTQJZko3ohbFPVtVnu+Ybk2zTrd8GWLqq11bVsVU1v6rmz549ezQFS5IkDVGLsywDHAdcXlXv7lt1OnBI9/wQ4POjrk2SJKmFFveyfCzwfOD7SS7q2t4IHAWcmuRQ4Frg2Q1qkyRJGrmRB7Kq+gaQSVbvO8paJEmSpgOv1C9JktSYgUySJKkxA5kkSVJjBjJJkqTGDGSSJEmNGcgkSZIaM5BJkiQ1ZiCTJElqzEAmSZLUmIFMkiSpMQOZJElSYwYySZKkxgxkkiRJjRnIJEmSGjOQSZIkNWYgkyRJasxAJkmS1JiBTJIkqTEDmSRJUmMGMkmSpMYMZJIkSY0ZyCRJkhozkEmSJDVmIJMkSWrMQCZJktSYgUySJKkxA5kkSVJjBjJJkqTGDGSSJEmNGcgkSZIaM5BJkiQ1ZiCTJElqzEAmSZLUmIFMkiSpMQOZJElSYwYySZKkxqZdIEuyX5IfJLkqyRGt65EkSRq2aRXIkmwA/AfwFGBX4KAku7atSpIkabimVSAD9gKuqqqrq+q3wCnAAY1rkiRJGqpUVesafifJM4H9qurvuuXnA4+sqsP7+iwAFnSLDwJ+MPJCR2cW8LPWRWiN+f2tv/zu1m9+f+uvmf7d7VBVs1e1YsNRV7K2qupY4NjWdYxCkoVVNb91HVozfn/rL7+79Zvf3/prnL+76XbI8npgu77luV2bJEnSjDXdAtl3gZ2T7JhkY+BA4PTGNUmSJA3VtDpkWVXLkxwOfBnYADi+qhY1LqulsTg0O4P5/a2//O7Wb35/66+x/e6m1aR+SZKkcTTdDllKkiSNHQOZJElSYwYySZKkxqbVpP5xl+TBwBzg/Kq6ra99v6o6q11lWp0kewFVVd/tbve1H3BFVZ3ZuDRpRuv+bh5A728n9C6VdHpVXd6uKq2pJCdV1cGt62jBSf3TRJKXA4cBlwO7A6+oqs936y6sqj1b1qfJJTmS3v1XNwTOBh4JfA14IvDlqnpHw/K0FpK8sMLRsRcAAAPmSURBVKo+1roOrVqS1wMH0bvN3uKueS69SyadUlVHtapNq5dk5ctaBdgH+G+Aqnr6yItqyEA2TST5PvDoqrotyTzgNODjVXVMku9V1R5NC9Skuu9ud2AT4AZgblXdmuSe9EY7H960QK2xJD+pqu1b16FVS/JD4CFVdedK7RsDi6pq5zaVaRBJLgQuAz4KFL1AdjK9QE1Vfb1ddaPnIcvp4x4Thymr6pokewOnJdmB3i+ppq/lVXUX8OskP6qqWwGq6vYkKxrXptVIcslkq4CtR1mL7rYVwLbAtSu1b9Ot0/Q2H3gF8CbgtVV1UZLbxy2ITTCQTR83Jtm9qi4C6EbKngocDzysbWlajd8m2ayqfg38n4nGJPfFfxTWB1sDTwZuWqk9wP+OvhzdDa8EzklyJXBd17Y9sBNweLOqNJCqWgG8J8mnu8cbGeNcMrYffBo6GFje31BVy4GDk3y4TUka0J9X1R3wuz8wEzYCDmlTku6GLwL3nvjPUL8k546+HA2qqs5KsguwF384qf+73ai11gNVtRh4VpL9gVtb19OKc8gkSZIa8zpkkiRJjRnIJEmSGjOQSZpRktw/ySlJfpTkgiRnJtklyaWta5OkyTipX9KMkSTAfwEnVtWBXdtuePkKSdOcI2SSZpJ9gDur6kMTDVV1Mb+/JAJJ5iX5nyQXdj+P6dq3SXJekouSXJrkcUk2SHJCt/z9JK/q+j4wyVndCNz/dLfvIcmzur4XJzlvtB9d0vrMETJJM8lDgQtW02cp8MSq+k2SneldGXw+8By6W10l2QDYjN4dGOZU1UMBkmzRbeNY4MVVdWWSRwIfAB4PvBl4clVd39dXklbLQCZp3GwEvD/J7sBdwC5d+3eB45NsBHyuu2r41cADkrwPOAP4SpJ7A48BPt07Qgr0bpsF8E3ghCSnAp8dzceRNBN4yFLSTLKIvrslTOJVwI3AbvRGxjYGqKrzgD+nd2HRE5IcXFU3df3OBV5M75579wBurqrd+37+tNvGi4F/BLYDLkiy1Tr+fJJmKAOZpJnkv4FNkiyYaEjycHoBacJ9gSXdXRWeD2zQ9dsBuLGqPkIveO2ZZBa9+8x+hl7Q2rO7V+mPkzyre126EwdI8sCqOr+q3gwsW+l9JWlSBjJJM0b1bj3yV8ATusteLAL+H3BDX7cPAIckuRh4MPCrrn1v4OIk3wP+BjiG3u14zk1yEfAJ4A1d3+cCh3bbWAQc0LW/q5v8fym9+2BePJxPKmmm8dZJkiRJjTlCJkmS1JiBTJIkqTEDmSRJUmMGMkmSpMYMZJIkSY0ZyCRJkhozkEmSJDVmIJMkSWrs/wM6kxGWyv2VHQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a8VZ5d8cg0p",
        "colab_type": "text"
      },
      "source": [
        "Bom, o desabalanceamento dos dados persistiu após o redimensionamento das classes, o que já era de se esperar. Fazendo uma análise do comportamento dos dados através desse gráfico, fica mais evidente a maiora dos alunos tem notas medianas, pois a classe 2, que representa o intervalo de notas entre 9 e 12, aparece com maior número de alunos. Lembrando que a escala de notas é de 0 a 20.\n",
        "\n",
        "Vamos treinar um novo modelo e ver seu resultado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvsiZ7lecgAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data.iloc[:,:-1]\n",
        "y = data.G3\n",
        "\n",
        "X = (X - X.min()) / (X.max() - X.min())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l_ccu_uhDOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_02 = RandomizedSearchCV(\n",
        "    MLPClassifier(),\n",
        "    param_grid,\n",
        "    cv=10,\n",
        "    scoring='accuracy'\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwgTsjWihTog",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "33e0beaf-1db5-449c-c60b-c9667fa46fd5"
      },
      "source": [
        "mlp_02.fit(X, y)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=10, error_score=nan,\n",
              "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                           batch_size='auto', beta_1=0.9,\n",
              "                                           beta_2=0.999, early_stopping=False,\n",
              "                                           epsilon=1e-08,\n",
              "                                           hidden_layer_sizes=(100,),\n",
              "                                           learning_rate='constant',\n",
              "                                           learning_rate_init=0.001,\n",
              "                                           max_fun=15000, max_iter=200,\n",
              "                                           momentum=0.9, n_iter_no_change=10,\n",
              "                                           nesterovs_momentum=True, power_t=0.5,\n",
              "                                           rando...\n",
              "                                           verbose=False, warm_start=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions=[{'activation': ['identity', 'logistic',\n",
              "                                                        'tanh', 'relu'],\n",
              "                                         'hidden_layer_sizes': [30, (50, 30),\n",
              "                                                                (50, 100),\n",
              "                                                                (30, 50, 100),\n",
              "                                                                (50, 150, 100)],\n",
              "                                         'max_iter': [500, 1000, 2000],\n",
              "                                         'solver': ['lbfgs', 'sgd', 'adam']}],\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ7YhrHrjA7D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "da6ea200-8e15-4025-c32c-0fb445976234"
      },
      "source": [
        "mlp_02_best_params = mlp_02.best_params_\n",
        "\n",
        "print('BEST PARAMETERS')\n",
        "for key, value in mlp_02_best_params.items():\n",
        "    print(key + ':', value)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BEST PARAMETERS\n",
            "solver: adam\n",
            "max_iter: 500\n",
            "hidden_layer_sizes: (50, 100)\n",
            "activation: logistic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QHflrn9jWSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6394dc5a-7d97-4a38-dc2f-1011e8a55ab8"
      },
      "source": [
        "print('Accuracy:', round(mlp_02.best_score_, 3)*100)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 71.89999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH_JVPZPjzXU",
        "colab_type": "text"
      },
      "source": [
        "## Discutindo resultados do segundo modelo\n",
        "\n",
        "O segundo modelo, escolhido no espaço de soluções, teve uma performance bem melhor do que o primeiro modelo. A melhora na acurácia deve estar relacionada ao processo de redimensionamento das classes que, mesmo com desbalanceamento das classes persistindo, a diferença entre elas diminuiu consideravelmente. Outro motivo da melhora no resultado se dá pelo fato de as novas classes terem dado uma maior significado ao comportamento dos dados, já que cada nova classe representa uma faixa de valores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQgGFCV72eVb",
        "colab_type": "text"
      },
      "source": [
        "## Treinando o modelo com balanceamento de dados utilizando resampling e diminuir o número de classes\n",
        "\n",
        "Nessa abordagem será feito uma reamostragem dos dados com o intuito de eliminar o desbalanceamento das classes. O método de reamostragem utilizado aqui serpa o **oversampling**, que consiste em criar novas instâncias - aleatoriamente - para as classes minoritárias a fim de igualar o total de instâncias de acordo com a classe majoritária. O efeito final do oversampling, além de igualar as classes, é o aumento de instâncias no dataset.\n",
        "\n",
        "No estado atual do dataset já temos as nossas classes redimensionadas (veja abaixo), então o que nos resta é fazer o oversampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WVoTg0_Hdad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1fe0f83e-1b65-4290-ac73-42a050a6a43a"
      },
      "source": [
        "print('Classes:')\n",
        "for i in data.G3.unique():\n",
        "    print(i)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classes:\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv-pZUnnHl7n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4f98f6e4-9d61-4e34-c222-33f18d4772e2"
      },
      "source": [
        "count_class_0 = data.query('G3 == 0').shape[0]\n",
        "count_class_1 = data.query('G3 == 1').shape[0]\n",
        "count_class_2 = data.query('G3 == 2').shape[0]\n",
        "count_class_3 = data.query('G3 == 3').shape[0]\n",
        "count_class_4 = data.query('G3 == 4').shape[0]\n",
        "\n",
        "print(\"Classe 0:\", count_class_0)\n",
        "print(\"Classe 1:\", count_class_1)\n",
        "print(\"Classe 2:\", count_class_2)\n",
        "print(\"Classe 3:\", count_class_3)\n",
        "print(\"Classe 4:\", count_class_4)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classe 0: 39\n",
            "Classe 1: 63\n",
            "Classe 2: 162\n",
            "Classe 3: 107\n",
            "Classe 4: 24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfX8fjwXLcup",
        "colab_type": "text"
      },
      "source": [
        "Acima temos a quantidade de instâncias por classe. Nas próximas duas células acontece as seguintes operações:\n",
        "\n",
        "- armazena-se as instâncias de cada classe;\n",
        "- em seguida a função `sample` é chamada pelos conjuntos que serão reamostrados pela classe majoritária, que no código é `count_class_2` e o parâmetro `replace` diz para a função se as alterações serão persistidas no objeto;\n",
        "- por fim, a função `pd.concat` cria um novo objeto `DataFrame` armazenado em `data_over`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W280HjdTKBT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "976b00e5-b919-4ff1-9886-b9cdacac2925"
      },
      "source": [
        "data_0 = data.query('G3 == 0')\n",
        "data_1 = data.query('G3 == 1')\n",
        "data_2 = data.query('G3 == 2')\n",
        "data_3 = data.query('G3 == 3')\n",
        "data_4 = data.query('G3 == 4')\n",
        "\n",
        "data_class_0_over = data_0.sample(count_class_2, replace=True)\n",
        "data_class_1_over = data_1.sample(count_class_2, replace=True)\n",
        "data_class_3_over = data_3.sample(count_class_2, replace=True)\n",
        "data_class_4_over = data_4.sample(count_class_2, replace=True)\n",
        "\n",
        "print(len(data_class_0_over))\n",
        "print(len(data_class_1_over))\n",
        "print(len(data_class_3_over))\n",
        "print(len(data_class_4_over))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162\n",
            "162\n",
            "162\n",
            "162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og65KGTxKp-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_over = pd.concat(\n",
        "    [data_class_0_over, data_class_1_over, data_2, data_class_3_over, data_class_4_over],\n",
        "    axis=0\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti0boYcnLWwT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "f17d4307-821b-4c5d-a12f-6dbf4c2ada83"
      },
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Total de instâncias')\n",
        "data_over.G3.value_counts().plot(kind='bar', title='Contagem de classes (G3)')\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAR2Sp1PNysZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data_over.iloc[:,:-1]\n",
        "y = data_over.G3\n",
        "\n",
        "X = (X - X.min()) / (X.max() - X.min())"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaBCq0vUOaXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_03 = RandomizedSearchCV(\n",
        "    MLPClassifier(),\n",
        "    param_grid,\n",
        "    cv=10,\n",
        "    scoring='accuracy'\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWosEz-pPE3Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "73e8f884-2bd2-4f49-9e55-8b3ca7e5e808"
      },
      "source": [
        "mlp_03.fit(X, y)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=10, error_score=nan,\n",
              "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                           batch_size='auto', beta_1=0.9,\n",
              "                                           beta_2=0.999, early_stopping=False,\n",
              "                                           epsilon=1e-08,\n",
              "                                           hidden_layer_sizes=(100,),\n",
              "                                           learning_rate='constant',\n",
              "                                           learning_rate_init=0.001,\n",
              "                                           max_fun=15000, max_iter=200,\n",
              "                                           momentum=0.9, n_iter_no_change=10,\n",
              "                                           nesterovs_momentum=True, power_t=0.5,\n",
              "                                           rando...\n",
              "                                           verbose=False, warm_start=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions=[{'activation': ['identity', 'logistic',\n",
              "                                                        'tanh', 'relu'],\n",
              "                                         'hidden_layer_sizes': [30, (50, 30),\n",
              "                                                                (50, 100),\n",
              "                                                                (30, 50, 100),\n",
              "                                                                (50, 150, 100)],\n",
              "                                         'max_iter': [500, 1000, 2000],\n",
              "                                         'solver': ['lbfgs', 'sgd', 'adam']}],\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQM9pPQRPJ1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fb559835-c92c-4a9f-830c-44f53069c735"
      },
      "source": [
        "mlp_03_best_params = mlp_03.best_params_\n",
        "\n",
        "print('BEST PARAMETERS')\n",
        "for key, value in mlp_03_best_params.items():\n",
        "    print(key + ':', value)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BEST PARAMETERS\n",
            "solver: adam\n",
            "max_iter: 1000\n",
            "hidden_layer_sizes: (50, 100)\n",
            "activation: relu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YovHyh5SDr_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "316ab61d-0870-425c-8e53-76dda2ac4a1b"
      },
      "source": [
        "print('Accuracy:', round(mlp_03.best_score_, 3)*100)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 91.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j8cK7uqTwjO",
        "colab_type": "text"
      },
      "source": [
        "## Discussão dos resultados\n",
        "\n",
        "O modelo 3 teve a melhor acurácia, cerca de 91%. Um ótimo número à primeira vista, mas vale discutir algumas coisas aqui sobre este trabalho:\n",
        "\n",
        "- Não estamos utilizando o mesmo modelo para comparar as 3 abordagens de pré-processamento de dados que foram definidas no início. A estratégia adoatada foi a utilização do método de otimização de parâmetros - utilizando o método random search - para obter o melhor conjunto de parâmetros para o modelo em cada abordagem de pré-processamento.\n",
        "\n",
        "- Vale frizar que o espaço de soluções utilizado foi o mesmo durante todo o trabalho.\n",
        "\n",
        "- Para a otimização de parâmetros, o método Random Search consegue escolher a melhor configuração para o modelo mas a sua característica de escolher, de forma randômica, um subconjunto do espaço de soluções, pode deixar de forma algum(ns) parâmetro(s) que poderiam ter uma performance melhor.\n",
        "\n",
        "- O dataset na sua forma original tem a variável `G3` como target, o que nos mostra que a tarefa de classificação é prever qual é a nota do aluno de acordo com suas características. Quando reduzimos o número de classes atribuindo uma faixa de valores a um novo valor, o trabalho de predição passa a ser \"a qual classe o(a) aluno(a) x pertence de acordo com suas características?\". Ter uma classe representando um conjunto de valores faz com que uma classe seja mais generalista no que diz respeito às características que pretencem a uma classe pode facilitar o treinamento do modelo porque ele precisa aprender os padrões relacionados a um conjunto menor de possibilidades."
      ]
    }
  ]
}